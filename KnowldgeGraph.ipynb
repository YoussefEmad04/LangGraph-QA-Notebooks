{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0630eff",
   "metadata": {},
   "source": [
    "Example using neo4j driver. This creates Movie nodes, Person nodes (actors+directors), Genre nodes, and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928b489",
   "metadata": {},
   "source": [
    "Use MERGE to avoid duplicates.\n",
    "\n",
    "Batch commits if dataset is big.\n",
    "\n",
    "Add indexes for performance: CREATE INDEX movie_title IF NOT EXISTS FOR (m:Movie) ON (m.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83accfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_huggingface\n",
      "  Using cached langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain_huggingface) (0.3.75)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain_huggingface) (0.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain_huggingface) (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (4.14.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.4.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.33.4->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\youssef\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.14.0)\n",
      "Using cached langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain_huggingface\n",
      "Successfully installed langchain_huggingface-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021909b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccca360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import GraphCypherQAChain, RetrievalQA, LLMChain\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d47506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv\"\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "def split_list(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    return [i.strip() for i in x.split(\"|\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9d7bb",
   "metadata": {},
   "source": [
    "## (:Movie)-[:DIRECTED]->(:Person)\n",
    "## (:Movie)-[:ACTED_IN]<-(:Person)\n",
    "## (:Movie)-[:IN_GENRE]->(:Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c107680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youssef\\AppData\\Local\\Temp\\ipykernel_24388\\2516480134.py:41: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(url=URI, username=USER, password=PASS)\n"
     ]
    }
   ],
   "source": [
    "URI = \"neo4j+s://896e87f9.databases.neo4j.io\"\n",
    "USER = \"neo4j\"\n",
    "PASS = \"XUJsOWG0NzbqTBIcEkCkslX0bSHlBmylyUa4kt8OQdU\"\n",
    "driver = GraphDatabase.driver(URI, auth=(USER, PASS))\n",
    "\n",
    "def ingest_row(tx, row): # find movie node with unique movie id\n",
    "    tx.run(\"\"\"\n",
    "    MERGE (m:Movie {movieId: $id})\n",
    "    SET m.title = $title, m.released = $released, m.imdbRating = $rating\n",
    "    \"\"\", id=int(row[\"movieId\"]), title=row[\"title\"],\n",
    "       released=str(row[\"released\"]), rating=float(row[\"imdbRating\"]) if not pd.isna(row[\"imdbRating\"]) else None)\n",
    "\n",
    "    if row.get(\"director\"): # create director node and relationship with movie\n",
    "        tx.run(\"\"\"\n",
    "        MERGE (d:Person {name: $name})\n",
    "        WITH d\n",
    "        MATCH (m:Movie {movieId: $id})\n",
    "        MERGE (d)-[:DIRECTED]->(m)\n",
    "        \"\"\", name=row[\"director\"], id=int(row[\"movieId\"]))\n",
    "\n",
    "    for actor in split_list(row.get(\"actors\", \"\")): # create actor nodes and relationships with movie loop ensure actor present as node\n",
    "        tx.run(\"\"\"\n",
    "        MERGE (p:Person {name: $actor}) \n",
    "        WITH p\n",
    "        MATCH (m:Movie {movieId: $id})\n",
    "        MERGE (p)-[:ACTED_IN]->(m)\n",
    "        \"\"\", actor=actor, id=int(row[\"movieId\"]))\n",
    "\n",
    "    for genre in split_list(row.get(\"genres\", \"\")): #Connects movies to their genres with [:IN_GENRE].\n",
    "        tx.run(\"\"\"\n",
    "        MERGE (g:Genre {name: $genre})\n",
    "        WITH g\n",
    "        MATCH (m:Movie {movieId: $id})\n",
    "        MERGE (m)-[:IN_GENRE]->(g)\n",
    "        \"\"\", genre=genre, id=int(row[\"movieId\"]))\n",
    "\n",
    "with driver.session() as sess: #Iterates through each row in the CSV (df.iterrows()).Calls ingest_row inside a write transaction to insert into Neo4j.\n",
    "    for _, row in df.iterrows():\n",
    "        sess.execute_write(ingest_row, row)\n",
    "\n",
    "graph = Neo4jGraph(url=URI, username=USER, password=PASS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047582c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [] #You loop over each row in the movies DataFrame. For each movie, you create a formatted text string containing its details (title, release date, director, actors, genres, and IMDB rating). You then create a Document object with this text and metadata (movieId and title) and append it to the docs list.\n",
    "from langchain.schema import Document\n",
    "#page_content → the text chunk used for embedding. metadata → a dictionary of metadata associated with the document.\n",
    "for _, r in df.iterrows():\n",
    "    text = f\"Title: {r.title}\\nReleased: {r.released}\\nDirector: {r.director}\\nActors: {r.actors}\\nGenres: {r.genres}\\nIMDB: {r.imdbRating}\"\n",
    "    docs.append(Document(page_content=text, metadata={\"movieId\": r.movieId, \"title\": r.title}))\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(docs, embeddings, collection_name=\"movies_kg_rag\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17658cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"question\": \"Who acted in Casino?\", \"query\": \"MATCH (m:Movie {{title: 'Casino'}})<-[:ACTED_IN]-(p:Person) RETURN p.name\"},\n",
    "    {\"question\": \"Who directed Toy Story?\", \"query\": \"MATCH (m:Movie {{title: 'Toy Story'}})<-[:DIRECTED]-(d:Person) RETURN d.name\"},\n",
    "    {\"question\": \"How many movies has Tom Hanks acted in?\", \"query\": \"MATCH (p:Person {{name: 'Tom Hanks'}})-[:ACTED_IN]->(m:Movie) RETURN COUNT(m)\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"query\"],\n",
    "    template=\"User input: {question}\\nCypher query: {query}\"\n",
    ")\n",
    "\n",
    "prefix = ( #This acts like the system prompt for your Cypher translator.\n",
    "    \"You are a Cypher expert. Use only MATCH/WITH/RETURN/COUNT. \"\n",
    "    \"Never generate CREATE/DELETE/SET. \"\n",
    "    \"Schema:\\n{schema}\\n\" #schema for the exact relationships in the KG\n",
    "    \"Generate ONLY the Cypher query.\\n\"\n",
    ")\n",
    "\n",
    "cypher_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=\"User input: {question}\\nCypher query:\",\n",
    "    input_variables=[\"schema\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e3e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youssef\\AppData\\Local\\Temp\\ipykernel_24388\\49973624.py:41: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  composer = LLMChain(llm=llm, prompt=compose_prompt)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
    "\n",
    "# Graph chain\n",
    "graph_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    llm=llm,\n",
    "    cypher_prompt=cypher_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "# RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Composer chain\n",
    "compose_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"graph_results\", \"docs\"],\n",
    "    template=\"\"\"\n",
    "Answer the question using both graph results and supporting documents.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Graph results:\n",
    "{graph_results}\n",
    "\n",
    "Docs:\n",
    "{docs}\n",
    "\n",
    "Return:\n",
    "- answer (1-2 sentences)\n",
    "- sources: whether from graph, docs, or both\n",
    "\"\"\"\n",
    ")\n",
    "composer = LLMChain(llm=llm, prompt=compose_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_answer(question):\n",
    "    graph_out = graph_chain.run(question)\n",
    "    docs_out = rag_chain.run(question)\n",
    "\n",
    "    return composer.run( #compose Then lets the LLM reason across both sources and produce a final answer.\n",
    "        question=question,\n",
    "        graph_results=graph_out,\n",
    "        docs=docs_out\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4f0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youssef\\AppData\\Local\\Temp\\ipykernel_24388\\515123713.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  graph_out = graph_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'Casino'})<-[:ACTED_IN]-(p:Person) RETURN p.name \n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'Robert De Niro'}, {'p.name': 'Joe Pesci'}, {'p.name': 'Sharon Stone'}, {'p.name': 'James Woods'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "- Robert De Niro, Joe Pesci, Sharon Stone, and James Woods acted in the movie Casino. \n",
      "- sources: both graph and docs \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'Schindler\\'s List'})-[r:IN_GENRE]->(g:Genre) RETURN g.name \n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Schindler's List is primarily considered a historical drama.  \n",
      "\n",
      "- sources: Docs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hybrid_answer(\"Who acted in the movie Casino?\"))\n",
    "print(hybrid_answer(\"List all genres of Schindler's List\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d552a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
